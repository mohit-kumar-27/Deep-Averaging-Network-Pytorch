{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DeepAveragingNetwork_Mohit_Final.ipynb","provenance":[{"file_id":"1CXeBm_Tlsnv0oeOpqOt2Wah13Oo6EA3a","timestamp":1660035353227}],"authorship_tag":"ABX9TyMfwS/+dEaornXC+qlaISm1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')\n","%cd /content/drive/'My Drive'/Assignment1/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0iwiL_MGvSTd","executionInfo":{"status":"ok","timestamp":1660041582615,"user_tz":-330,"elapsed":2927,"user":{"displayName":"MOHIT KUMAR","userId":"11239845291709820487"}},"outputId":"07028ffb-ba6d-42bc-ed00-ce03cb1e07fd"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","/content/drive/My Drive/Assignment1\n"]}]},{"cell_type":"code","source":["import gensim.downloader as api\n","import gensim\n","import torch\n","import torch.nn as nn\n","import numpy as np\n","from torch.utils.data import Dataset\n","from torch.nn.utils import clip_grad_norm_\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"a1tkiL6ALTpR","executionInfo":{"status":"ok","timestamp":1660041582616,"user_tz":-330,"elapsed":6,"user":{"displayName":"MOHIT KUMAR","userId":"11239845291709820487"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["pretrained_model=\"glove-wiki-gigaword-300\"\n","wv = api.load(pretrained_model)"],"metadata":{"id":"OeJ0DzcnpPIH","executionInfo":{"status":"ok","timestamp":1660041659352,"user_tz":-330,"elapsed":76741,"user":{"displayName":"MOHIT KUMAR","userId":"11239845291709820487"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def load_data():\n","    data = list()\n","    with open('Train.neg', mode='rb') as f:\n","      Content = f.read()\n","    neg_samples = Content.splitlines()\n","    label = 1\n","    for s in neg_samples:\n","      s_text = gensim.utils.simple_preprocess(s)\n","      data.append((s_text, label))\n","    with open('Train.pos', mode='rb') as f:\n","      Content = f.read()\n","    pos_samples = Content.splitlines()\n","    label = 0\n","    for s in pos_samples:\n","      s_text = gensim.utils.simple_preprocess(s)\n","      data.append((s_text, label))\n","    return data"],"metadata":{"id":"wXuCbF5ZO3fE","executionInfo":{"status":"ok","timestamp":1660041659353,"user_tz":-330,"elapsed":7,"user":{"displayName":"MOHIT KUMAR","userId":"11239845291709820487"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["def load_words():\n","    words = set()\n","    UNK = '<unk>'\n","    word2ind = {UNK: 0}\n","    ind2word = {0: UNK}\n","    for w in wv.vocab.keys():\n","      words.add(w)\n","    words = sorted(words)\n","    for w in words:\n","        idx = len(word2ind)\n","        word2ind[w] = idx\n","        ind2word[idx] = w\n","    words = [UNK] + words\n","    return words, word2ind, ind2word\n","\n","\n","def vectorize_sample(s, word2ind):\n","    sample_text, sample_label = s\n","    vec_text = [0] * len(sample_text)\n","\n","    for i in range(len(sample_text)):\n","        try:\n","            vec_text[i] = word2ind[sample_text[i]]\n","        except KeyError:\n","            vec_text[i] = word2ind['<unk>']\n","\n","    return vec_text, sample_label\n","\n","class Sample_Dataset(Dataset):\n","\n","    def __init__(self, samples, word2ind):\n","        self.samples = samples\n","        self.word2ind = word2ind\n","\n","    def __getitem__(self, index):\n","        return vectorize_sample(self.samples[index], self.word2ind)\n","\n","    def __len__(self):\n","        return len(self.samples)\n","\n","def create_batch(batch):\n","    sample_len = list()\n","    label_list = list()\n","    for s in batch:\n","        sample_len.append(len(s[0]))\n","        label_list.append(s[1])\n","    target_labels = torch.LongTensor(label_list)\n","    x1 = torch.LongTensor(len(sample_len), max(sample_len)).zero_()\n","    for i in range(len(sample_len)):\n","        sample_text = batch[i][0]\n","        vec = torch.LongTensor(sample_text)\n","        x1[i, :len(sample_text)].copy_(vec)\n","    s_batch = {'text': x1, 'length': torch.FloatTensor(sample_len), 'labels': target_labels}\n","    return s_batch\n","\n","\n","def evaluate(data_loader, model, device):\n","    model.eval()\n","    num_examples = 0\n","    error = 0\n","\n","    for idx, batch in enumerate(data_loader):\n","        sample_text = batch['text'].to(device)\n","        sample_len = batch['length']\n","        labels = batch['labels']\n","        \n","        logits = model(torch.LongTensor(sample_text), torch.tensor(sample_len))\n","        top_n, top_i = logits.topk(1)\n","\n","        error += torch.nonzero(top_i.squeeze() - torch.LongTensor(labels)).size(0)\n","        num_examples += sample_text.size(0)\n","    accuracy = 1 - error / num_examples\n","    print('Accuracy : ', accuracy)\n","    return accuracy\n","\n","\n","def train(args, model, train_loader, test_loader, accuracy, device):\n","    model.train()\n","    optimizer = torch.optim.Adamax(model.parameters())\n","    criterion = nn.CrossEntropyLoss()\n","\n","    for idx, batch in enumerate(train_loader):\n","        sample_text = batch['text'].to(device)\n","        sample_length = batch['length']\n","        labels = batch['labels']\n","\n","        model.zero_grad()\n","        out = model(torch.LongTensor(sample_text), torch.tensor(sample_length))\n","        loss = criterion(out, batch['labels'])\n","        loss.backward()\n","        optimizer.step()\n","\n","        clip_grad_norm_(model.parameters(), int(args['grad_clipping']))\n","\n","        if idx % int(args['checkpoint']) == 0 and idx > 0:\n","            print('Iteration No: %d' % (idx))\n","            curr_accuracy = evaluate(test_loader, model, device)\n","            if accuracy < curr_accuracy:\n","                torch.save(model, args['save_model'])\n","                accuracy = curr_accuracy\n","    return accuracy\n","\n","def create_emb_layer(weights_matrix):\n","    num_embeddings, embedding_dim = weights_matrix.size()\n","    emb_layer = nn.Embedding(num_embeddings, embedding_dim)\n","    emb_layer.load_state_dict({'weight': weights_matrix})\n","    emb_layer.weight.requires_grad = False\n","\n","    return emb_layer, num_embeddings, embedding_dim\n","\n","\n","class DAN_Model(nn.Module):\n","\n","    def __init__(self, n_classes, weights_matrix,\n","                 hidden_dim=300, dropout=.5):\n","        super(DAN_Model, self).__init__()\n","        self.n_classes = n_classes\n","        self.hidden_dim = hidden_dim\n","        self.dropout = dropout\n","        \n","        self.embeddings, num_embeddings, embedding_dim = create_emb_layer(weights_matrix)\n","        self.linear1 = nn.Linear(embedding_dim, hidden_dim)\n","        self.linear2 = nn.Linear(hidden_dim, n_classes)\n","        self.classifier = nn.Sequential(self.linear1, nn.ReLU(), self.linear2)\n","        self._softmax = nn.Softmax()\n","\n","    def forward(self, input_text, text_len):\n","        logits = None\n","        text_embed = self.embeddings(input_text)\n","        encoded = text_embed.sum(1)\n","        encoded /= text_len.view(text_embed.size(0), -1)\n","        logits = self.classifier(encoded)\n","        return self._softmax(logits)"],"metadata":{"id":"hwNoOvHdllqI","executionInfo":{"status":"ok","timestamp":1660041659353,"user_tz":-330,"elapsed":6,"user":{"displayName":"MOHIT KUMAR","userId":"11239845291709820487"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["args = {\n","'batch_size': 16,\n","'num_epochs': 20,\n","'grad_clipping': 5,\n","'save_model': 'sentiment.pt',\n","'load_model': 'sentiment.pt',\n","'num_classes': 2,\n","'checkpoint': 50,\n","}\n","\n","args['cuda'] = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if args['cuda'] else \"cpu\")\n","\n","data = load_data()\n","\n","voc, word2ind, ind2word = load_words()\n","\n","weights_matrix = np.random.random((len(voc),300))\n","i=1\n","for word in voc[1:]:\n","  weights_matrix[i,:] = wv[word]\n","  i += 1\n","\n","weights_matrix = torch.from_numpy(weights_matrix)\n","model = DAN_Model(args['num_classes'], weights_matrix)\n","model.to(device)\n","print(model)\n","train_data, val_data = train_test_split(data, test_size=0.3, random_state=42)\n","\n","train_dataset = Sample_Dataset(train_data, word2ind)\n","train_sampler = torch.utils.data.sampler.RandomSampler(train_dataset)\n","\n","val_dataset = Sample_Dataset(val_data, word2ind)\n","val_sampler = torch.utils.data.sampler.SequentialSampler(val_dataset)\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=args['batch_size'],\n","                                        sampler=val_sampler, num_workers=0,\n","                                        collate_fn=create_batch)\n","        \n","accuracy = 0\n","for epoch in range(args['num_epochs']):\n","    print('---------------------------------------------------------------------------------------------')\n","    print('Epoch %d' % epoch)\n","    print('---------------------------------------------------------------------------------------------')\n","    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args['batch_size'],\n","                                        sampler=train_sampler, num_workers=0,\n","                                        collate_fn=create_batch)\n","    accuracy = train(args, model, train_loader, val_loader, accuracy, device)\n","# print('start testing:\\n')\n","\n","# test_dataset = Sample_Dataset(test_exs, word2ind)\n","# test_sampler = torch.utils.data.sampler.SequentialSampler(test_dataset)\n","# test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args['batch_size'],\n","#                                         sampler=test_sampler, num_workers=0,\n","#                                         collate_fn=create_batch)\n","# evaluate(test_loader, model, device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ox3UkTfnuaVF","executionInfo":{"status":"ok","timestamp":1660041776854,"user_tz":-330,"elapsed":117505,"user":{"displayName":"MOHIT KUMAR","userId":"11239845291709820487"}},"outputId":"f8429dc2-f492-49cf-9411-d6da998e099a"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["DAN_Model(\n","  (embeddings): Embedding(400001, 300)\n","  (linear1): Linear(in_features=300, out_features=300, bias=True)\n","  (linear2): Linear(in_features=300, out_features=2, bias=True)\n","  (classifier): Sequential(\n","    (0): Linear(in_features=300, out_features=300, bias=True)\n","    (1): ReLU()\n","    (2): Linear(in_features=300, out_features=2, bias=True)\n","  )\n","  (_softmax): Softmax(dim=None)\n",")\n","Epoch 0\n","---------------------------------------------------------------------------------------------\n","Iteration No: 50\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:88: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:133: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:67: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"]},{"output_type":"stream","name":"stdout","text":["Accuracy :  0.5093333333333334\n","Iteration No: 100\n","Accuracy :  0.5093333333333334\n","Iteration No: 150\n","Accuracy :  0.5246666666666666\n","Iteration No: 200\n","Accuracy :  0.534\n","Iteration No: 250\n","Accuracy :  0.5783333333333334\n","Iteration No: 300\n","Accuracy :  0.5366666666666666\n","Iteration No: 350\n","Accuracy :  0.5836666666666667\n","Iteration No: 400\n","Accuracy :  0.4993333333333333\n","Epoch 1\n","---------------------------------------------------------------------------------------------\n","Iteration No: 50\n","Accuracy :  0.6659999999999999\n","Iteration No: 100\n","Accuracy :  0.6166666666666667\n","Iteration No: 150\n","Accuracy :  0.6126666666666667\n","Iteration No: 200\n","Accuracy :  0.5853333333333333\n","Iteration No: 250\n","Accuracy :  0.6253333333333333\n","Iteration No: 300\n","Accuracy :  0.637\n","Iteration No: 350\n","Accuracy :  0.5489999999999999\n","Iteration No: 400\n","Accuracy :  0.6376666666666666\n","Epoch 2\n","---------------------------------------------------------------------------------------------\n","Iteration No: 50\n","Accuracy :  0.5509999999999999\n","Iteration No: 100\n","Accuracy :  0.625\n","Iteration No: 150\n","Accuracy :  0.6753333333333333\n","Iteration No: 200\n","Accuracy :  0.6493333333333333\n","Iteration No: 250\n","Accuracy :  0.6933333333333334\n","Iteration No: 300\n","Accuracy :  0.6799999999999999\n","Iteration No: 350\n","Accuracy :  0.6633333333333333\n","Iteration No: 400\n","Accuracy :  0.6619999999999999\n","Epoch 3\n","---------------------------------------------------------------------------------------------\n","Iteration No: 50\n","Accuracy :  0.6\n","Iteration No: 100\n","Accuracy :  0.6543333333333333\n","Iteration No: 150\n","Accuracy :  0.6776666666666666\n","Iteration No: 200\n","Accuracy :  0.6973333333333334\n","Iteration No: 250\n","Accuracy :  0.6256666666666666\n","Iteration No: 300\n","Accuracy :  0.5880000000000001\n","Iteration No: 350\n","Accuracy :  0.604\n","Iteration No: 400\n","Accuracy :  0.6053333333333333\n","Epoch 4\n","---------------------------------------------------------------------------------------------\n","Iteration No: 50\n","Accuracy :  0.567\n","Iteration No: 100\n","Accuracy :  0.7023333333333333\n","Iteration No: 150\n","Accuracy :  0.6943333333333334\n","Iteration No: 200\n","Accuracy :  0.688\n","Iteration No: 250\n","Accuracy :  0.6656666666666666\n","Iteration No: 300\n","Accuracy :  0.7136666666666667\n","Iteration No: 350\n","Accuracy :  0.7066666666666667\n","Iteration No: 400\n","Accuracy :  0.7016666666666667\n","Epoch 5\n","---------------------------------------------------------------------------------------------\n","Iteration No: 50\n","Accuracy :  0.6763333333333333\n","Iteration No: 100\n","Accuracy :  0.7150000000000001\n","Iteration No: 150\n","Accuracy :  0.7206666666666667\n","Iteration No: 200\n","Accuracy :  0.6983333333333333\n","Iteration No: 250\n","Accuracy :  0.7016666666666667\n","Iteration No: 300\n","Accuracy :  0.7173333333333334\n","Iteration No: 350\n","Accuracy :  0.6639999999999999\n","Iteration No: 400\n","Accuracy :  0.7056666666666667\n","Epoch 6\n","---------------------------------------------------------------------------------------------\n","Iteration No: 50\n","Accuracy :  0.7043333333333333\n","Iteration No: 100\n","Accuracy :  0.7206666666666667\n","Iteration No: 150\n","Accuracy :  0.7213333333333334\n","Iteration No: 200\n","Accuracy :  0.6876666666666666\n","Iteration No: 250\n","Accuracy :  0.6966666666666667\n","Iteration No: 300\n","Accuracy :  0.7196666666666667\n","Iteration No: 350\n","Accuracy :  0.6476666666666666\n","Iteration No: 400\n","Accuracy :  0.7016666666666667\n","Epoch 7\n","---------------------------------------------------------------------------------------------\n","Iteration No: 50\n","Accuracy :  0.5273333333333333\n","Iteration No: 100\n","Accuracy :  0.6376666666666666\n","Iteration No: 150\n","Accuracy :  0.6903333333333334\n","Iteration No: 200\n","Accuracy :  0.7183333333333333\n","Iteration No: 250\n","Accuracy :  0.7173333333333334\n","Iteration No: 300\n","Accuracy :  0.7116666666666667\n","Iteration No: 350\n","Accuracy :  0.724\n","Iteration No: 400\n","Accuracy :  0.7143333333333333\n","Epoch 8\n","---------------------------------------------------------------------------------------------\n","Iteration No: 50\n","Accuracy :  0.7306666666666667\n","Iteration No: 100\n","Accuracy :  0.73\n","Iteration No: 150\n","Accuracy :  0.6426666666666667\n","Iteration No: 200\n","Accuracy :  0.6993333333333334\n","Iteration No: 250\n","Accuracy :  0.7206666666666667\n","Iteration No: 300\n","Accuracy :  0.722\n","Iteration No: 350\n","Accuracy :  0.7143333333333333\n","Iteration No: 400\n","Accuracy :  0.652\n","Epoch 9\n","---------------------------------------------------------------------------------------------\n","Iteration No: 50\n","Accuracy :  0.726\n","Iteration No: 100\n","Accuracy :  0.725\n","Iteration No: 150\n","Accuracy :  0.7206666666666667\n","Iteration No: 200\n","Accuracy :  0.7393333333333334\n","Iteration No: 250\n","Accuracy :  0.7233333333333334\n","Iteration No: 300\n","Accuracy :  0.6859999999999999\n","Iteration No: 350\n","Accuracy :  0.7170000000000001\n","Iteration No: 400\n","Accuracy :  0.714\n","Epoch 10\n","---------------------------------------------------------------------------------------------\n","Iteration No: 50\n","Accuracy :  0.6950000000000001\n","Iteration No: 100\n","Accuracy :  0.7073333333333334\n","Iteration No: 150\n","Accuracy :  0.7130000000000001\n","Iteration No: 200\n","Accuracy :  0.7326666666666667\n","Iteration No: 250\n","Accuracy :  0.714\n","Iteration No: 300\n","Accuracy :  0.665\n","Iteration No: 350\n","Accuracy :  0.736\n","Iteration No: 400\n","Accuracy :  0.6356666666666666\n","Epoch 11\n","---------------------------------------------------------------------------------------------\n","Iteration No: 50\n","Accuracy :  0.548\n","Iteration No: 100\n","Accuracy :  0.7146666666666667\n","Iteration No: 150\n","Accuracy :  0.6346666666666667\n","Iteration No: 200\n","Accuracy :  0.63\n","Iteration No: 250\n","Accuracy :  0.729\n","Iteration No: 300\n","Accuracy :  0.6846666666666666\n","Iteration No: 350\n","Accuracy :  0.733\n","Iteration No: 400\n","Accuracy :  0.732\n","Epoch 12\n","---------------------------------------------------------------------------------------------\n","Iteration No: 50\n","Accuracy :  0.7186666666666667\n","Iteration No: 100\n","Accuracy :  0.735\n","Iteration No: 150\n","Accuracy :  0.613\n","Iteration No: 200\n","Accuracy :  0.7406666666666666\n","Iteration No: 250\n","Accuracy :  0.7336666666666667\n","Iteration No: 300\n","Accuracy :  0.6703333333333333\n","Iteration No: 350\n","Accuracy :  0.7276666666666667\n","Iteration No: 400\n","Accuracy :  0.663\n","Epoch 13\n","---------------------------------------------------------------------------------------------\n","Iteration No: 50\n","Accuracy :  0.7363333333333333\n","Iteration No: 100\n","Accuracy :  0.742\n","Iteration No: 150\n","Accuracy :  0.7306666666666667\n","Iteration No: 200\n","Accuracy :  0.677\n","Iteration No: 250\n","Accuracy :  0.7066666666666667\n","Iteration No: 300\n","Accuracy :  0.601\n","Iteration No: 350\n","Accuracy :  0.7386666666666667\n","Iteration No: 400\n","Accuracy :  0.7436666666666667\n","Epoch 14\n","---------------------------------------------------------------------------------------------\n","Iteration No: 50\n","Accuracy :  0.7333333333333334\n","Iteration No: 100\n","Accuracy :  0.7353333333333334\n","Iteration No: 150\n","Accuracy :  0.712\n","Iteration No: 200\n","Accuracy :  0.7053333333333334\n","Iteration No: 250\n","Accuracy :  0.6813333333333333\n","Iteration No: 300\n","Accuracy :  0.7333333333333334\n","Iteration No: 350\n","Accuracy :  0.7333333333333334\n","Iteration No: 400\n","Accuracy :  0.742\n","Epoch 15\n","---------------------------------------------------------------------------------------------\n","Iteration No: 50\n","Accuracy :  0.6396666666666666\n","Iteration No: 100\n","Accuracy :  0.7246666666666667\n","Iteration No: 150\n","Accuracy :  0.6913333333333334\n","Iteration No: 200\n","Accuracy :  0.7286666666666667\n","Iteration No: 250\n","Accuracy :  0.7453333333333334\n","Iteration No: 300\n","Accuracy :  0.7146666666666667\n","Iteration No: 350\n","Accuracy :  0.6819999999999999\n","Iteration No: 400\n","Accuracy :  0.7283333333333333\n","Epoch 16\n","---------------------------------------------------------------------------------------------\n","Iteration No: 50\n","Accuracy :  0.6653333333333333\n","Iteration No: 100\n","Accuracy :  0.7273333333333334\n","Iteration No: 150\n","Accuracy :  0.7043333333333333\n","Iteration No: 200\n","Accuracy :  0.7456666666666667\n","Iteration No: 250\n","Accuracy :  0.673\n","Iteration No: 300\n","Accuracy :  0.602\n","Iteration No: 350\n","Accuracy :  0.723\n","Iteration No: 400\n","Accuracy :  0.6863333333333334\n","Epoch 17\n","---------------------------------------------------------------------------------------------\n","Iteration No: 50\n","Accuracy :  0.7383333333333333\n","Iteration No: 100\n","Accuracy :  0.7276666666666667\n","Iteration No: 150\n","Accuracy :  0.73\n","Iteration No: 200\n","Accuracy :  0.6696666666666666\n","Iteration No: 250\n","Accuracy :  0.7236666666666667\n","Iteration No: 300\n","Accuracy :  0.7346666666666667\n","Iteration No: 350\n","Accuracy :  0.7466666666666666\n","Iteration No: 400\n","Accuracy :  0.7146666666666667\n","Epoch 18\n","---------------------------------------------------------------------------------------------\n","Iteration No: 50\n","Accuracy :  0.6203333333333334\n","Iteration No: 100\n","Accuracy :  0.7373333333333334\n","Iteration No: 150\n","Accuracy :  0.698\n","Iteration No: 200\n","Accuracy :  0.6646666666666667\n","Iteration No: 250\n","Accuracy :  0.716\n","Iteration No: 300\n","Accuracy :  0.7090000000000001\n","Iteration No: 350\n","Accuracy :  0.719\n","Iteration No: 400\n","Accuracy :  0.677\n","Epoch 19\n","---------------------------------------------------------------------------------------------\n","Iteration No: 50\n","Accuracy :  0.6963333333333334\n","Iteration No: 100\n","Accuracy :  0.739\n","Iteration No: 150\n","Accuracy :  0.7343333333333333\n","Iteration No: 200\n","Accuracy :  0.728\n","Iteration No: 250\n","Accuracy :  0.7343333333333333\n","Iteration No: 300\n","Accuracy :  0.7443333333333333\n","Iteration No: 350\n","Accuracy :  0.7343333333333333\n","Iteration No: 400\n","Accuracy :  0.645\n"]}]}]}